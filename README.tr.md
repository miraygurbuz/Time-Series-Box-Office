[![en](https://img.shields.io/badge/lang-en-blue.svg)](https://github.com/miraygurbuz/Time-Series-Box-Office/blob/main/README.md)
[![tr](https://img.shields.io/badge/lang-tr-red.svg)](https://github.com/miraygurbuz/Time-Series-Box-Office/blob/main/README.tr.md)
# ðŸŽ¬ GiÅŸe Verilerine GÃ¶re HasÄ±lat Tahmini
Bu projede, transformer tabanlÄ± modeller kullanÄ±larak gÃ¼nlÃ¼k giÅŸe hasÄ±latlarÄ±nÄ±n tahmin edilmesi amaÃ§lanmaktadÄ±r.
## Proje HakkÄ±nda
GÃ¼nlÃ¼k giÅŸe verileri, [Box Office Mojo](https://www.boxofficemojo.com/date/) web sitesinden Python kullanÄ±larak toplanmÄ±ÅŸtÄ±r. Veri toplama sÃ¼recinde Selenium, BeautifulSoup4 ve Requests kÃ¼tÃ¼phaneleri kullanÄ±lmÄ±ÅŸtÄ±r. Toplanan veriler Ã¼zerinde eksik verilerin tamamlanmasÄ±, trend ve mevsimsellik bileÅŸenlerine ayrÄ±ÅŸtÄ±rma, otokorelasyon analizi ve Ã¶zellik mÃ¼hendisliÄŸi adÄ±mlarÄ± uygulanmÄ±ÅŸtÄ±r.

Projenin ikinci kÄ±smÄ±nda, Transformer tabanlÄ± modeller kullanÄ±larak giÅŸe hasÄ±lat tahmini gerÃ§ekleÅŸtirilmiÅŸtir.

### KullanÄ±lan modeller:
- Autoformer
- TFT (Temporal Fusion Transformer)
- Informer
- FEDformer
- VanillaTransformer

### KullanÄ±lan KÃ¼tÃ¼phaneler
- Selenium, BeautifulSoup4, Requests
- Statsmodels
- NeuralForecast

## Kurulum
* Projeyi klonlayÄ±n:
```
git clone https://github.com/miraygurbuz/Time-Series-Box-Office.git
```
* Gereksinimleri yÃ¼kleyin:
```
pip install -r requirements.txt
```

## KullanÄ±m
### 1. Veri KazÄ±ma
* Ã‡alÄ±ÅŸmakta olduÄŸunuz tarayÄ±cÄ±ya uygun sÃ¼rÃ¼cÃ¼yÃ¼ `driver` klasÃ¶re eklemeniz gerekmektedir.

   * **Chrome iÃ§in:** chromedriver dosyasÄ±nÄ± indirin ve `driver` klasÃ¶rÃ¼ne yerleÅŸtirin.
   * **Firefox iÃ§in:** geckodriver dosyasÄ±nÄ± indirin ve  `driver` klasÃ¶rÃ¼ne yerleÅŸtirin.
  
> â—**Not:** SÃ¼rÃ¼cÃ¼yÃ¼ `driver` klasÃ¶rÃ¼ne ekledikten sonra `scraper/settings.py` dosyasÄ±nÄ±n `DRIVER_PATH` kÄ±smÄ±nÄ± gÃ¼ncelleyerek sÃ¼rÃ¼cÃ¼ yolunu belirtin.
* `scraper.py` dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±n:
```
python scraper/scraper.py
```

### 2. Veri Ã–n Ä°ÅŸleme
#### Uygulanan AdÄ±mlar:
* Eksik Verilerin DoldurulmasÄ±
* Zaman DeÄŸiÅŸkenlerinin Eklenmesi
* Zaman Serisinin Yeniden Ã–rneklenmesi
* Zaman Serisinin Trend ve Mevsimsellik BileÅŸenlerine AyrÄ±ÅŸtÄ±rÄ±lmasÄ±
* Otokorelasyon Analizi
* Ã–zellik MÃ¼hendisliÄŸi
  
Veri Ã¶n iÅŸleme adÄ±mlarÄ±nÄ± Jupyter Notebook veya Python scripti kullanarak gerÃ§ekleÅŸtirebilirsiniz:
* Jupyter Notebook ile:
```
jupyter notebook data_preprocessing/data_preprocessing.ipynb
```
* Python scripti ile:
```
python data_preprocessing/main.py
```
### 3. Transformer TabanlÄ± Modeller
Transformer tabanlÄ± modellerin eÄŸitimi ve deÄŸerlendirilmesi Google Colab ortamÄ±nda gerÃ§ekleÅŸtirilmiÅŸtir. 
  
DetaylÄ± model eÄŸitim sÃ¼recine eriÅŸmek iÃ§in Google Colab baÄŸlantÄ±sÄ±nÄ± kullanabilirsiniz:

[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/gist/miraygurbuz/e26773471c3ba83e45a00a9cef97f7b5/transformers.ipynb)

## SonuÃ§lar 
### Hata Metrikleri

| Model               | MAPE (%)| MAE (milyon) | MSE (trilyon) | RMSE (milyon) | R-squared (%)|
|---------------------|---------|--------------|---------------|---------------|------------|
| Autoformer          | 10,80 | 1,30         | 3,03          | 1,74          | 99,29     |
| TFT                 | 2,59  | 0,64         | 0,86          | 0,93          | 99,80     |
| Informer            | 4,05  | 0,60         | 0,58          | 0,76          | 99,73     |
| FEDformer           | 8,74  | 1,11         | 2,11          | 1,45          | 99,51     |
| VanillaTransformer  | 3,03  | 0,44         | 0,30          | 0,55          | 99,93     |

Hata metrikleri incelendiÄŸinde VanillaTransformer modelinin en iyi performansÄ± sergilediÄŸi gÃ¶rÃ¼lmektedir. En dÃ¼ÅŸÃ¼k MAPE ve MAE deÄŸerlerine sahip olmasÄ± hata oranÄ±nÄ±n daha dÃ¼ÅŸÃ¼k olduÄŸunu ve daha stabil tahminler Ã¼rettiÄŸini gÃ¶stermekte, diÄŸer modellere kÄ±yasla daha dÃ¼ÅŸÃ¼k RMSE deÄŸerine sahip olmasÄ± da daha tutarlÄ± tahminler yaptÄ±ÄŸÄ±nÄ± ortaya koymaktadÄ±r.

TFT ve Informer modelleri ise birbirine yakÄ±n performans gÃ¶stererek Autoformer ve FEDformer modellerine gÃ¶re daha baÅŸarÄ±lÄ± sonuÃ§lar Ã¼retmiÅŸtir.

Autoformer modeli ise diÄŸer modellere kÄ±yasla daha dÃ¼ÅŸÃ¼k bir performans gÃ¶stermiÅŸtir.

**Genel Performans SÄ±ralamasÄ±:**

VanillaTransformer > Informer â‰¥ TFT > FEDformer > Autoformer ÅŸeklindedir.
